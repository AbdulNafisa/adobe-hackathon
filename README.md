# Adobe India Hackathon 2025

## ðŸŽ¯ Project Overview

This repository contains my solutions for the **Adobe India Hackathon 2025**, featuring intelligent document processing and persona-driven content analysis systems. The project demonstrates advanced PDF processing capabilities and intelligent content extraction based on specific user personas and job requirements.

## ðŸ“‹ Challenges Completed

### **Challenge 1a: PDF Processing and Structure Extraction**
- **Objective**: Extract document structure, titles, and hierarchical outlines from PDF documents
- **Technology**: PyMuPDF, Python, Docker
- **Key Features**: Dual-strategy PDF processing, intelligent heading detection, schema-compliant JSON output
- **Performance**: < 10 seconds for 50-page PDFs, < 200MB model size

### **Challenge 1b: Persona-Driven Document Intelligence**
- **Objective**: Extract and prioritize relevant content based on specific personas and job-to-be-done requirements
- **Technology**: PyMuPDF, pdfminer.six, Python, Docker
- **Key Features**: Multi-persona analysis, relevance scoring, structured content extraction
- **Performance**: < 60 seconds for 3-5 documents, < 1GB model size

## ðŸ—ï¸ Project Structure

```
ADOBE HACKATHON/
â”œâ”€â”€ Challenge_1a/                    # PDF Processing Solution
â”‚   â”œâ”€â”€ process_pdfs.py             # Main processing script
â”‚   â”œâ”€â”€ Dockerfile                  # Container configuration
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ README.md                   # Challenge 1a documentation
â”‚   â””â”€â”€ sample_dataset/             # Sample data and schema
â”‚       â”œâ”€â”€ pdfs/                   # Input PDF files
â”‚       â”œâ”€â”€ outputs/                # Generated JSON outputs
â”‚       â””â”€â”€ schema/                 # Output schema definition
â”‚
â”œâ”€â”€ Challenge_1b/                    # Persona-Driven Analysis Solution
â”‚   â”œâ”€â”€ process_collections_final.py # Main processing script
â”‚   â”œâ”€â”€ test_processing.py          # Test validation script
â”‚   â”œâ”€â”€ Dockerfile                  # Container configuration
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ README.md                   # Challenge 1b documentation
â”‚   â”œâ”€â”€ approach_explanation.md     # Methodology explanation
â”‚   â””â”€â”€ Collection 1/               # Travel Planning collection
â”‚   â”œâ”€â”€ Collection 2/               # Adobe Acrobat Learning collection
â”‚   â””â”€â”€ Collection 3/               # Recipe Collection
â”‚
â””â”€â”€ README.md                       # This file
```

## ðŸš€ Quick Start

### **Prerequisites**
- Python 3.10 or higher
- Docker
- 8 CPUs and 16GB RAM available

### **Challenge 1a: PDF Processing**
```bash
# Navigate to Challenge 1a
cd Challenge_1a

# Build Docker image
docker build --platform linux/amd64 -t challenge1a-processor .

# Run with sample data
docker run --rm -v $(pwd)/sample_dataset/pdfs:/app/input:ro -v $(pwd)/sample_dataset/outputs:/app/output --network none challenge1a-processor
```

### **Challenge 1b: Persona-Driven Analysis**
```bash
# Navigate to Challenge 1b
cd Challenge_1b

# Build Docker image
docker build --platform linux/amd64 -t challenge1b-processor .

# Run with sample collections
docker run --rm -v $(pwd)/Collection_1:/app/collection challenge1b-processor python process_collections_final.py collection
```

## ðŸ› ï¸ Technology Stack

### **Core Technologies**
- **Python 3.10**: Primary programming language
- **PyMuPDF (fitz)**: Advanced PDF processing and text extraction
- **pdfminer.six**: Fallback PDF processing library
- **Docker**: Containerization for consistent deployment
- **JSON Schema**: Structured output validation

### **Key Libraries**
- **PyMuPDF**: Primary PDF text extraction and document analysis
- **pdfminer.six**: Alternative PDF processing for compatibility
- **Python Standard Library**: json, pathlib, re, logging, datetime

### **No Machine Learning Models**
- Rule-based algorithms and heuristics
- No external ML models or APIs required
- All processing done locally without internet access

## ðŸ“Š Performance Metrics

### **Challenge 1a Performance**
- **Processing Time**: < 10 seconds for 50-page PDFs
- **Model Size**: < 200MB
- **Memory Usage**: Efficient handling within 16GB RAM
- **CPU Utilization**: Optimized for 8 CPU cores

### **Challenge 1b Performance**
- **Processing Time**: < 60 seconds for 3-5 documents
- **Model Size**: < 1GB
- **Memory Usage**: Efficient multi-collection processing
- **CPU Utilization**: Optimized for 8 CPU cores

## ðŸŽ¯ Key Features

### **Challenge 1a: Advanced PDF Processing**
- **Dual-Strategy Processing**: TOC extraction + multi-signal detection
- **Intelligent Heading Detection**: Font size, formatting, and pattern analysis
- **Title Extraction**: Metadata-first approach with fallback strategies
- **Outline Cleaning**: Fragment merging, duplicate removal, validation
- **Schema Compliance**: Output conforms to predefined JSON schema

### **Challenge 1b: Persona-Driven Intelligence**
- **Multi-Persona Support**: Travel Planner, HR Professional, Food Contractor
- **Relevance Scoring**: Keyword-based algorithms with job alignment
- **Section Identification**: Advanced pattern recognition and header detection
- **Content Prioritization**: Importance ranking based on persona and task
- **Structured Output**: Metadata, extracted sections, and subsection analysis

## ðŸ”§ Architecture

### **Modular Design**
Both challenges employ modular architectures for scalability and maintainability:

- **PDFProcessor**: Handles text extraction and document analysis
- **ContentAnalyzer**: Processes and structures extracted content
- **OutputGenerator**: Creates schema-compliant JSON output
- **Containerization**: Docker-based deployment for consistency

### **Error Handling**
- Robust error handling for corrupted PDFs
- Fallback strategies for different PDF formats
- Memory management for large documents
- Processing timeout protection

## ðŸ“ˆ Testing and Validation

### **Challenge 1a Testing**
```bash
# Test with sample dataset
docker run --rm -v $(pwd)/sample_dataset/pdfs:/app/input:ro -v $(pwd)/sample_dataset/outputs:/app/output --network none challenge1a-processor
```

### **Challenge 1b Testing**
```bash
# Run comprehensive tests
python test_processing.py

# Expected output:
# Collection 1: âœ… PASS
# Collection 2: âœ… PASS  
# Collection 3: âœ… PASS
# Overall: 3/3 collections processed successfully
```

## ðŸš€ Deployment

### **Docker Deployment**
Both solutions are containerized for easy deployment:

```bash
# Build images
docker build --platform linux/amd64 -t challenge1a-processor ./Challenge_1a
docker build --platform linux/amd64 -t challenge1b-processor ./Challenge_1b

# Run containers
docker run --rm -v $(pwd)/input:/app/input:ro -v $(pwd)/output:/app/output --network none challenge1a-processor
docker run --rm -v $(pwd)/collection:/app/collection challenge1b-processor python process_collections_final.py collection
```

### **Resource Requirements**
- **Platform**: AMD64 architecture
- **Runtime**: CPU-only (no GPU required)
- **Memory**: < 16GB RAM
- **CPU**: 8 cores available
- **Network**: No internet access during execution

## ðŸ“š Documentation

### **Detailed Documentation**
- **[Challenge 1a README](./Challenge_1a/README.md)**: Complete PDF processing documentation
- **[Challenge 1b README](./Challenge_1b/README.md)**: Persona-driven analysis documentation
- **[Approach Explanation](./Challenge_1b/approach_explanation.md)**: Methodology and technical details

### **Code Documentation**
- Well-commented source code
- Clear function and class documentation
- Comprehensive error handling
- Performance optimization notes

## ðŸŽ–ï¸ Challenge Compliance

### **All Requirements Met**
- âœ… **Performance Constraints**: All timing and resource limits satisfied
- âœ… **Architecture Requirements**: AMD64 compatible, CPU-only processing
- âœ… **Output Format**: Schema-compliant JSON output
- âœ… **Containerization**: Docker-based deployment
- âœ… **Open Source**: All libraries and tools are open source
- âœ… **Offline Operation**: No internet access required during execution

### **Quality Assurance**
- âœ… **Comprehensive Testing**: All test cases pass
- âœ… **Error Handling**: Robust error management
- âœ… **Documentation**: Complete technical documentation
- âœ… **Performance**: Optimized for speed and efficiency

## ðŸ¤ Contributing

This project was developed for the Adobe India Hackathon 2025. The solutions demonstrate:

- **Innovation**: Advanced PDF processing techniques
- **Scalability**: Modular architecture for easy extension
- **Reliability**: Robust error handling and fallback strategies
- **Performance**: Optimized for speed and resource efficiency

## ðŸ“„ License

This project is developed for the Adobe India Hackathon 2025. All solutions are original work demonstrating advanced document processing and intelligent content analysis capabilities.

## ðŸ† Results

### **Challenge 1a Results**
- âœ… Successfully processes PDF documents
- âœ… Extracts document structure and outlines
- âœ… Generates schema-compliant JSON output
- âœ… Meets all performance constraints

### **Challenge 1b Results**
- âœ… Processes multiple document collections
- âœ… Extracts persona-relevant content
- âœ… Ranks content by importance
- âœ… Generates structured analysis output
- âœ… All 3 collections processed successfully

---

**ðŸŽ‰ Both challenges completed successfully with all requirements met!**
